{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/train.csv')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/test.csv')\n",
    "# test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['image_id']=df['image_id']+\".jpg\"\n",
    "# test_df['image_id']=test_df['image_id']+\".jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from torchvision import datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2                \n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score\n",
    "from albumentations import *\n",
    "from albumentations.pytorch import ToTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet-pytorch\r\n",
      "  Downloading efficientnet_pytorch-0.6.3.tar.gz (16 kB)\r\n",
      "Requirement already satisfied, skipping upgrade: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet-pytorch) (1.4.0)\r\n",
      "Building wheels for collected packages: efficientnet-pytorch\r\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-py3-none-any.whl size=12419 sha256=3430f94da19c3cff8fd160bd7efc9d8aefbafafe570922ec2b60c1bdc8cbbd2f\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/90/6b/0c/f0ad36d00310e65390b0d4c9218ae6250ac579c92540c9097a\r\n",
      "Successfully built efficientnet-pytorch\r\n",
      "Installing collected packages: efficientnet-pytorch\r\n",
      "Successfully installed efficientnet-pytorch-0.6.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade efficientnet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# train_df,valid_df=train_test_split(df,test_size=0.2,shuffle=True,random_state=23,stratify=df.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.reset_index(drop=True,inplace=True)\n",
    "# valid_df.reset_index(drop=True,inplace=True)\n",
    "test_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,df,root_dir,transform=None,iftest=False):\n",
    "        self.df=df\n",
    "        self.root_dir=root_dir\n",
    "        self.transform=transform\n",
    "        self.iftest=iftest\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx=idx.tolist()\n",
    "        img_name=self.root_dir+self.df.iloc[idx,0]+'.jpg'\n",
    "#         print(img_name)\n",
    "        image= cv2.imread(img_name,cv2.IMREAD_COLOR)\n",
    "#         image= cv2.imread(img_name)\n",
    "#         print(img_name,image)\n",
    "        image= cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "#         image = Image.fromarray(image)\n",
    "#         print(type(image))\n",
    "        if self.transform:\n",
    "            image=self.transform(image=image)['image']\n",
    "        if self.iftest:\n",
    "            return image\n",
    "        labels=torch.tensor(np.argmax(self.df.iloc[idx,1:].values))\n",
    "#         labels=np.asarray(labels)\n",
    "#         labels=torch.from_numpy(labels.astype(np.int32))\n",
    "#         labels=labels.unsqueeze(-1)\n",
    "#         print(labels.shape)\n",
    "#         sample={'image':image,'labels':labels}\n",
    "        return (image,labels)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMSIZE=545\n",
    "IMSIZE=EfficientNet.get_image_size('efficientnet-b5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456\n"
     ]
    }
   ],
   "source": [
    "print(IMSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=CustomDataset(df=train_df,root_dir='/kaggle/input/plant-pathology-2020-fgvc7/images/',\n",
    "                     transform=Compose([augmentations.transforms.Resize(height=IMSIZE,width=IMSIZE,always_apply=True),\n",
    "                                                  HorizontalFlip(p=0.5),\n",
    "                                                  VerticalFlip(p=0.5),\n",
    "                                                  ShiftScaleRotate(rotate_limit=25.0,p=0.7),\n",
    "                                                  OneOf([IAAEmboss(p=1),IAASharpen(p=1),Blur(p=1)],p=0.5),\n",
    "                                                  IAAPiecewiseAffine(p=0.5),\n",
    "                                                   Normalize((0.485,0.456,0.406),\n",
    "                                                                      (0.229,0.224,0.225),always_apply=True),\n",
    "                                                  ToTensor()\n",
    "                                                  ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_dataset=CustomDataset(df=valid_df,root_dir='/kaggle/input/plant-pathology-2020-fgvc7/images/',\n",
    "#                      transform=Compose([augmentations.transforms.Resize(height=IMSIZE,width=IMSIZE,always_apply=True),\n",
    "#                                                    Normalize((0.485,0.456,0.406),\n",
    "#                                                                       (0.229,0.224,0.225),always_apply=True),\n",
    "#                                                     ToTensor()\n",
    "#                                                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset=CustomDataset(df=test_df,root_dir='/kaggle/input/plant-pathology-2020-fgvc7/images/',\n",
    "                     transform=Compose([augmentations.transforms.Resize(height=IMSIZE,width=IMSIZE,always_apply=True),\n",
    "                                                  Normalize((0.485,0.456,0.406),\n",
    "                                                                      (0.229,0.224,0.225),always_apply=True),\n",
    "                                                    ToTensor()\n",
    "                                                  ]),iftest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=2)\n",
    "# valid_loader=DataLoader(valid_dataset,batch_size=BATCH_SIZE,shuffle=False,num_workers=2)\n",
    "test_loader=DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=False,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    device='cuda:0'\n",
    "use_tpu=False\n",
    "use_device=True\n",
    "if use_tpu:\n",
    "    device='idk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_transfer=models.densenet161(pretrained=True)\n",
    "# # for param in model_transfer.parameters():\n",
    "# #     param.requires_grad=False\n",
    "# print(model_transfer)\n",
    "# model_transfer.classifier=nn.Sequential(nn.Linear(model_transfer.classifier.in_features,1000),\n",
    "#                                         nn.ReLU(),\n",
    "#                                         nn.Dropout(p=0.5),\n",
    "#                                         nn.Linear(1000,4))\n",
    "# # nn.init.kaiming_normal_(model_transfer.classifier.weight, nonlinearity='relu')\n",
    "# if use_device:\n",
    "#     model_transfer = model_transfer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEPOCHS=30\n",
    "# print(IMSIZE)\n",
    "# criterion_transfer = nn.CrossEntropyLoss()\n",
    "# learning_rate=5e-4*np.logspace(0,1.5,9)\n",
    "# learning_rate=learning_rate[2]\n",
    "# learning_rate=8e-4\n",
    "# optimizer_transfer = optim.AdamW(model_transfer.parameters(),learning_rate,weight_decay=1e-3)\n",
    "# num_train_steps = int(len(train_dataset) / BATCH_SIZE * NEPOCHS)\n",
    "# from transformers import get_cosine_schedule_with_warmup\n",
    "# scheduler = get_cosine_schedule_with_warmup(optimizer_transfer, num_warmup_steps=len(train_dataset)/BATCH_SIZE*5, num_training_steps=num_train_steps)\n",
    "# # optimizer_transfer = torch.optim.Adam(model_efficient.parameters())\n",
    "# # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_transfer, 'max', patience = 3,verbose=True,min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs,train_loader,valid_loader,model,optimizer,criterion,use_device,save_path,final_train=False,ifsched=False):\n",
    "    for epoch in range(1,n_epochs+1):\n",
    "        train_loss=0.0\n",
    "        valid_loss=0.0\n",
    "        labels_for_acc=[]\n",
    "        output_for_acc=[]\n",
    "        labels_for_accv=[]\n",
    "        output_for_accv=[]\n",
    "        model.train()\n",
    "        for batch_idx,(data,target) in enumerate(train_loader):\n",
    "#             print(type(data),type(target))\n",
    "            if use_device:\n",
    "                data,target=data.to(device),target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output=model(data)\n",
    "            loss=criterion(output,target)\n",
    "            train_loss+=loss.item()*data.size(0)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if ifsched:\n",
    "                    scheduler.step()\n",
    "            labels_for_acc=np.concatenate((labels_for_acc,target.cpu().numpy()),0)\n",
    "            output_for_acc=np.concatenate((output_for_acc,np.argmax(output.cpu().detach().numpy(),1)),0)\n",
    "        train_loss=train_loss/len(train_loader.dataset)\n",
    "        train_acc=accuracy_score(labels_for_acc,output_for_acc)\n",
    "        if not final_train:\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                for batch_idx,(data,target) in enumerate(valid_loader):\n",
    "                    if use_device:\n",
    "                        data,target=data.to(device),target.to(device)\n",
    "                    output=model(data)\n",
    "                    loss=criterion(output,target)\n",
    "                    valid_loss+=loss.item()*data.size(0)\n",
    "                    labels_for_accv=np.concatenate((labels_for_accv,target.cpu().numpy()),0)\n",
    "                    output_for_accv=np.concatenate((output_for_accv,np.argmax(output.cpu().detach().numpy(),1)),0)\n",
    "                valid_loss=valid_loss/len(valid_loader.dataset)\n",
    "                valid_acc=accuracy_score(labels_for_accv,output_for_accv)\n",
    "                print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tTrain Acc: {:.6f} \\tValidation Acc: {:.6f}'.format(\n",
    "                epoch, \n",
    "                train_loss,\n",
    "                valid_loss,\n",
    "                train_acc,\n",
    "                valid_acc\n",
    "                ))\n",
    "        if final_train:\n",
    "            print('Epoch: {} \\tTraining Loss: {:.6f} \\tTrain Acc: {:.6f} '.format(\n",
    "                epoch, \n",
    "                train_loss,\n",
    "                train_acc\n",
    "                ))\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(NEPOCHS, train_loader,valid_loader, model_transfer, optimizer_transfer, criterion_transfer, use_device, 'model_transfer.pt',ifsched=True,final_train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b7-dcc49843.pth\" to /root/.cache/torch/checkpoints/efficientnet-b7-dcc49843.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965870380f43424fa72f9dde768aff7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=266860719.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded pretrained weights for efficientnet-b7\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "model_efficient=EfficientNet.from_pretrained('efficientnet-b7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in model_efficient.parameters():\n",
    "#     param.requires_grad=False\n",
    "# print(model_transfer)\n",
    "model_efficient._fc=nn.Sequential(nn.Linear(model_efficient._fc.in_features,1000,bias=True),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(p=0.5),\n",
    "                                 nn.Linear(1000,4,bias=True))\n",
    "# nn.init.kaiming_normal_(model_efficient._fc.weight, nonlinearity='relu')\n",
    "if use_device:\n",
    "    model_efficient = model_efficient.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456\n"
     ]
    }
   ],
   "source": [
    "NEPOCHS=40\n",
    "print(IMSIZE)\n",
    "criterion_transfer = nn.CrossEntropyLoss()\n",
    "# learning_rate=5e-4*np.logspace(0,1.5,9)\n",
    "# learning_rate=learning_rate[2]\n",
    "learning_rate=8e-4\n",
    "optimizer_transfer = optim.AdamW(model_efficient.parameters(),learning_rate,weight_decay=1e-3)\n",
    "num_train_steps = int(len(train_dataset) / BATCH_SIZE * NEPOCHS)\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer_transfer, num_warmup_steps=len(train_dataset)/BATCH_SIZE*5, num_training_steps=num_train_steps)\n",
    "# optimizer_transfer = torch.optim.Adam(model_efficient.parameters())\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_transfer, 'max', patience = 3,verbose=True,min_lr=0.00001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.879696 \tTrain Acc: 0.660626 \n",
      "Epoch: 2 \tTraining Loss: 0.501540 \tTrain Acc: 0.834157 \n",
      "Epoch: 3 \tTraining Loss: 0.441545 \tTrain Acc: 0.868204 \n",
      "Epoch: 4 \tTraining Loss: 0.462158 \tTrain Acc: 0.861614 \n",
      "Epoch: 5 \tTraining Loss: 0.452874 \tTrain Acc: 0.870401 \n",
      "Epoch: 6 \tTraining Loss: 0.407235 \tTrain Acc: 0.878089 \n",
      "Epoch: 7 \tTraining Loss: 0.409521 \tTrain Acc: 0.872597 \n",
      "Epoch: 8 \tTraining Loss: 0.330252 \tTrain Acc: 0.908841 \n",
      "Epoch: 9 \tTraining Loss: 0.327630 \tTrain Acc: 0.895113 \n",
      "Epoch: 10 \tTraining Loss: 0.282577 \tTrain Acc: 0.914882 \n",
      "Epoch: 11 \tTraining Loss: 0.263643 \tTrain Acc: 0.922021 \n",
      "Epoch: 12 \tTraining Loss: 0.277589 \tTrain Acc: 0.915431 \n",
      "Epoch: 13 \tTraining Loss: 0.283966 \tTrain Acc: 0.919824 \n",
      "Epoch: 14 \tTraining Loss: 0.251000 \tTrain Acc: 0.920373 \n",
      "Epoch: 15 \tTraining Loss: 0.247314 \tTrain Acc: 0.930258 \n",
      "Epoch: 16 \tTraining Loss: 0.212032 \tTrain Acc: 0.940143 \n",
      "Epoch: 17 \tTraining Loss: 0.184947 \tTrain Acc: 0.941790 \n",
      "Epoch: 18 \tTraining Loss: 0.193263 \tTrain Acc: 0.936848 \n",
      "Epoch: 19 \tTraining Loss: 0.160169 \tTrain Acc: 0.948380 \n",
      "Epoch: 20 \tTraining Loss: 0.173940 \tTrain Acc: 0.941241 \n",
      "Epoch: 21 \tTraining Loss: 0.163953 \tTrain Acc: 0.947831 \n",
      "Epoch: 22 \tTraining Loss: 0.183057 \tTrain Acc: 0.943438 \n",
      "Epoch: 23 \tTraining Loss: 0.127837 \tTrain Acc: 0.956068 \n",
      "Epoch: 24 \tTraining Loss: 0.101050 \tTrain Acc: 0.964305 \n",
      "Epoch: 25 \tTraining Loss: 0.137269 \tTrain Acc: 0.953871 \n",
      "Epoch: 26 \tTraining Loss: 0.098145 \tTrain Acc: 0.969248 \n",
      "Epoch: 27 \tTraining Loss: 0.096568 \tTrain Acc: 0.967600 \n",
      "Epoch: 28 \tTraining Loss: 0.073690 \tTrain Acc: 0.971444 \n",
      "Epoch: 29 \tTraining Loss: 0.074884 \tTrain Acc: 0.974739 \n",
      "Epoch: 30 \tTraining Loss: 0.066816 \tTrain Acc: 0.975837 \n",
      "Epoch: 31 \tTraining Loss: 0.047211 \tTrain Acc: 0.984075 \n",
      "Epoch: 32 \tTraining Loss: 0.046847 \tTrain Acc: 0.983526 \n",
      "Epoch: 33 \tTraining Loss: 0.049694 \tTrain Acc: 0.981878 \n",
      "Epoch: 34 \tTraining Loss: 0.037877 \tTrain Acc: 0.985722 \n",
      "Epoch: 35 \tTraining Loss: 0.036254 \tTrain Acc: 0.987919 \n",
      "Epoch: 36 \tTraining Loss: 0.033315 \tTrain Acc: 0.989017 \n",
      "Epoch: 37 \tTraining Loss: 0.035489 \tTrain Acc: 0.989566 \n",
      "Epoch: 38 \tTraining Loss: 0.024235 \tTrain Acc: 0.991214 \n",
      "Epoch: 39 \tTraining Loss: 0.024066 \tTrain Acc: 0.993959 \n",
      "Epoch: 40 \tTraining Loss: 0.028442 \tTrain Acc: 0.991763 \n"
     ]
    }
   ],
   "source": [
    "train(NEPOCHS, train_loader,None, model_efficient, optimizer_transfer, criterion_transfer, use_device, 'model_transfer.pt',ifsched=True,final_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,test_loader,use_device):\n",
    "    preds_for_output=np.zeros((1,4))\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for images in test_loader:\n",
    "            if use_device:\n",
    "                images=images.to(device)\n",
    "            preds=model(images)\n",
    "            preds_for_output=np.concatenate((preds_for_output,preds.cpu().detach().numpy()),0)\n",
    "    return preds_for_output\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs=5\n",
    "import scipy\n",
    "subs=[]\n",
    "for i in range(num_runs):\n",
    "    out=test(model_efficient,test_loader,use_device)\n",
    "    output=pd.DataFrame(scipy.special.softmax(out,1),columns=['healthy','multiple_diseases','rust','scab'])\n",
    "    output.drop(0,inplace=True)\n",
    "    output.reset_index(drop=True,inplace=True)\n",
    "    subs.append(output)\n",
    "\n",
    "sub_eff=sum(subs)/num_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df['image_id']=test_df['image_id'].str.replace('.jpg','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>healthy</th>\n",
       "      <th>multiple_diseases</th>\n",
       "      <th>rust</th>\n",
       "      <th>scab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test_0</td>\n",
       "      <td>9.674879e-07</td>\n",
       "      <td>6.745189e-05</td>\n",
       "      <td>9.999316e-01</td>\n",
       "      <td>1.858236e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test_1</td>\n",
       "      <td>1.182380e-07</td>\n",
       "      <td>1.569633e-05</td>\n",
       "      <td>9.999842e-01</td>\n",
       "      <td>1.697371e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test_2</td>\n",
       "      <td>2.448064e-07</td>\n",
       "      <td>1.282778e-05</td>\n",
       "      <td>3.456888e-12</td>\n",
       "      <td>9.999869e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test_3</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>1.620882e-07</td>\n",
       "      <td>2.786629e-09</td>\n",
       "      <td>6.635890e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Test_4</td>\n",
       "      <td>3.173216e-07</td>\n",
       "      <td>1.387625e-05</td>\n",
       "      <td>9.999858e-01</td>\n",
       "      <td>4.692372e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id       healthy  multiple_diseases          rust          scab\n",
       "0   Test_0  9.674879e-07       6.745189e-05  9.999316e-01  1.858236e-09\n",
       "1   Test_1  1.182380e-07       1.569633e-05  9.999842e-01  1.697371e-10\n",
       "2   Test_2  2.448064e-07       1.282778e-05  3.456888e-12  9.999869e-01\n",
       "3   Test_3  9.999998e-01       1.620882e-07  2.786629e-09  6.635890e-08\n",
       "4   Test_4  3.173216e-07       1.387625e-05  9.999858e-01  4.692372e-10"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub1=sub_eff.copy()\n",
    "sub1['image_id']=test_df.image_id\n",
    "sub1=sub1[['image_id','healthy','multiple_diseases','rust','scab']]\n",
    "sub1.to_csv('sub_densenet.csv',index=False)\n",
    "sub1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "34af13b72d4c4678900cd05fb27d62fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "51e7c3eb159b4d3392f8eab60b8e1e26": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8a30051ee4a64c60805a81a924ac0ade": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9408dff8567b4c09bc6f8f4794a1e48a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_51e7c3eb159b4d3392f8eab60b8e1e26",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_b8de9ca663cb4f6e9d242628b3d2f0b3",
       "value": " 254M/254M [00:03&lt;00:00, 79.3MB/s]"
      }
     },
     "965870380f43424fa72f9dde768aff7a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_db3f45ec96bb44bb9f14001feb56c12b",
        "IPY_MODEL_9408dff8567b4c09bc6f8f4794a1e48a"
       ],
       "layout": "IPY_MODEL_34af13b72d4c4678900cd05fb27d62fb"
      }
     },
     "b8de9ca663cb4f6e9d242628b3d2f0b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "db3f45ec96bb44bb9f14001feb56c12b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8a30051ee4a64c60805a81a924ac0ade",
       "max": 266860719,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ee523a8c2a3c4654bd621c094bbe59f2",
       "value": 266860719
      }
     },
     "ee523a8c2a3c4654bd621c094bbe59f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
